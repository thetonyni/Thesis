---
title: "generating-missing-data"
author: "Tony Ni"
date: "9/18/2020"
output: pdf_document
---

Playing around with how to make vectors and datasets with missing values...

Some websites/sources:

https://cran.r-project.org/web/packages/missMethods/vignettes/Generating-missing-values.html
https://rmisstastic.netlify.app/how-to/generate/misssimul

Look through this website:
https://www.itrcweb.org/gsmc-1/Content/GW%20Stats/5%20Methods%20in%20indiv%20Topics/5%207%20Nondetects.htm#:~:text=Robust%20ROS%20is%20semi%2Dparametric,are%20made%20for%20the%20nondetects.&text=ROS%20assumes%20that%20all%20data,non%2Dnegative)%20statistical%20population.

```{r}
library(tidyverse)
library(missMethods) #package for generating missing data
library(NADA) #package for mle for left censored data
```

## Generating missing data

Assuming log-normal distribution, which is the most common distribution for censored water data, (refer to technotes pdf file) for contaminant values in groundwater data...

Ok let's just try to pull random numbers from a logormal(1, 1) distribution for a "artificial" dataset.

```{r}
set.seed(7271999)

num <- 1000

m <- 1
s <- 1
location <- log(m^2 / sqrt(s^2 + m^2))
shape <- sqrt(log(1 + (s^2 / m^2)))
print(paste("location:", location))
print(paste("shape:", shape))

id <- seq(1, num, by = 1)
value <- rlnorm(num, location, shape)

my_df <- as.data.frame(cbind(id, value))
```

Now, to play around with the methods in the `missMethods` package. These methods let us generate missing values in a dataset, in our case -- the artificial dataset we generated above.

```{r}
my_df2 <- delete_MAR_censoring(ds = my_df, #dataframe
                     p = 0.3, #probability that a value is missing
                     cols_mis = "id",
                     cols_ctrl = "value")

glimpse(my_df2)
```

Uh... I don't think the methods in this package are what we're looking for... This `delete_MAR_censoring` "generate MAR values using a censoring mechanism. This leads to a missing value in `id`, if the value is below the 30% quantile of `value`" We really only have 1 numeric variable of interest here...

Maybe we can just do it by hand...

Let's just say something like, for any value below `some number`, we make a new column and mark it as being censored/below limit of detection. I just chose 0.5 as a completely arbitrary value...

```{r}
threshold <- 0.3

my_df3 <- my_df %>%
  mutate(below_detection = case_when(value <= threshold ~ "T",
                                     value > threshold ~ "F"))
tibble(my_df3)
```

Great! This is basically the general format of how missing values are encoded in the groundwater data -- there is a variable called called `<` which is `<` is the value is below the LOD and left blank ` ` if not. This is exactly what we want! This is a bit weird because it doesn't make sense to have negative concentrations, but it's not worth it to try to fix it since we just want some artificial dataset to work with at the moment (may be in the future though)...


## Playing around with missing data

Now, we want to try playing around with this dataset, let's try seeing what our sample mean and sd are -- as a comparison point.

```{r}
mean(my_df3$value)
sd(my_df3$value)
```

Now, let's make the values for which the observations in which `below_detection` is `T` -- NA.

```{r}
my_df4 <- my_df3 %>%
  mutate(value = if_else(
    below_detection == "F", value, NA_real_))

glimpse(my_df4)
```


### Substitution Approach

Ok, let's true our substitution approach where we impute in the missing values with value/2 and value/sqrt(2). Um... for this artificial dataset, we don't really have a LOD but let's make it an arbitrary value 9.

First, replacing all our missing values with LOD/2

```{r}
lod_div_2 <- my_df4 %>%
  mutate(value = if_else(
  below_detection == "T", 9/2, value))

mean(lod_div_2$value)
sd(lod_div_2$value)
```

Next, replacing all our missing value with LOD/sqrt(2)

```{r}
lod_div_sqrt2 <- my_df4 %>%
  mutate(value = if_else(
  below_detection == "T", 9/sqrt(2), value))

mean(lod_div_sqrt2$value)
sd(lod_div_sqrt2$value)
```

We know the true population mean and sd of the distribution we pulled samples from is lognormal(1, 1)

The sample mean and sd of our artificial dataset is 0.95 and 0.905 respectively.

The mean and sd we get from LOD/2 substitution method yields 1.56 amd 1.46 respectively.

The mean and sd we get from LOD/sqrt(2 substitution method yields 1.82 and 2.02 respectively.

We can see that this method is OK... It doesn't really capture the true mean and sd very well...

### MLE Approach

Now using the MLE approach, we can use the `cen_mle` function to compute statistics when the data contains left-censored values.

```{r}
my_df5 <- my_df4 %>%
  mutate(below_detection = as.logical(below_detection))

mle_res = cenmle(my_df5$value, my_df5$below_detection, conf.int=0.95, dist = "gaussian")

mean(mle_res)
sd(mle_res)
```

We obtain a mean of 1.08 and sd of 0.92. This method performs much better than the substitution method!

### Kaplan Meier Approach

This method doesn't have any distributional assumptions, which is an advantage it has over the MLE approach:

```{r}
km_res = cenfit(my_df$value, my_df5$below_detection, conf.int=0.95)
plot(km_res) #plots cdf of value

mean(km_res)
sd(km_res)
```

We obtain a mean of 0.97 and sd of 0.89. This method is comparable to the MLE method!

### Imputation Method with MLE

### Imputation Method with KM












